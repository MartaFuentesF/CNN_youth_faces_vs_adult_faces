{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03adf5fc-5d2f-42c5-b563-c332c30b3aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.applications import VGG19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ed576f-5e1e-4f4c-b2e0-0813e4b236f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14633 files belonging to 2 classes.\n",
      "Using 11707 files for training.\n",
      "Found 14633 files belonging to 2 classes.\n",
      "Using 2926 files for validation.\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/marta/Documents/data_dir/'\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(256, 256),\n",
    "  batch_size = 64)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(256, 256),\n",
    "  batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8176629d-1359-47bc-b673-1784c814d941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.349409811877536, 1: 0.794322006296819}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helped by Argishti Ovsepyan \n",
    "classes = np.array(['PLP', 'POR'])\n",
    "y = [classes[0]] * 5422 + [classes[1]] * 9211\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=y)\n",
    "\n",
    "class_weights_dict = class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a47be7-157c-4233-b886-58bac1542a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learning rate scheduler\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77f1e45b-fde8-409f-81ae-7c00325c6196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Add dropout layers\n",
    "cnn5 = Sequential()\n",
    "\n",
    "cnn5.add(Conv2D(512, 3, activation='relu', input_shape=(256, 256, 3)))\n",
    "cnn5.add(MaxPooling2D(2, padding='same'))\n",
    "cnn5.add(Dropout(0.5))\n",
    "\n",
    "cnn5.add(Conv2D(256, 3, activation='relu', kernel_regularizer=regularizers.l2(0.03)))\n",
    "cnn5.add(MaxPooling2D(2, padding='same'))\n",
    "cnn5.add(Dropout(0.5))\n",
    "\n",
    "cnn5.add(Conv2D(256, 3, activation='relu', kernel_regularizer=regularizers.l2(0.03)))\n",
    "cnn5.add(MaxPooling2D(2, padding='same'))\n",
    "cnn5.add(Dropout(0.5))\n",
    "\n",
    "cnn5.add(Conv2D(256, 3, activation='relu', kernel_regularizer=regularizers.l2(0.03)))\n",
    "cnn5.add(MaxPooling2D(2, padding='same'))\n",
    "cnn5.add(Dropout(0.5))\n",
    "\n",
    "cnn5.add(Flatten())\n",
    "cnn5.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn5.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92579976-e446-4a9b-8543-e361fc71758e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 09:13:19.835194: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_17' with dtype double and shape [2]\n",
      "\t [[{{node Placeholder/_17}}]]\n",
      "2024-06-12 09:13:19.835451: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_17' with dtype double and shape [2]\n",
      "\t [[{{node Placeholder/_17}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - ETA: 0s - loss: 24.7043 - acc: 0.5303 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 10:49:21.300827: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [2926]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2024-06-12 10:49:21.301880: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [2926]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 6134s 34s/step - loss: 24.7043 - acc: 0.5303 - val_loss: 14.7167 - val_acc: 0.6237 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "183/183 [==============================] - 6298s 34s/step - loss: 11.6314 - acc: 0.5724 - val_loss: 9.1202 - val_acc: 0.6193 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "183/183 [==============================] - 5567s 30s/step - loss: 7.4746 - acc: 0.5815 - val_loss: 6.0685 - val_acc: 0.6203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "183/183 [==============================] - 6589s 36s/step - loss: 5.1101 - acc: 0.5912 - val_loss: 4.2459 - val_acc: 0.6268 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "183/183 [==============================] - 5739s 31s/step - loss: 3.6564 - acc: 0.5877 - val_loss: 3.1016 - val_acc: 0.6247 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "183/183 [==============================] - 4717s 26s/step - loss: 2.7098 - acc: 0.5978 - val_loss: 2.3312 - val_acc: 0.6230 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "183/183 [==============================] - 4768s 26s/step - loss: 2.0752 - acc: 0.6000 - val_loss: 1.8253 - val_acc: 0.6073 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "154/183 [========================>.....] - ETA: 12:38 - loss: 1.6717 - acc: 0.5966"
     ]
    }
   ],
   "source": [
    "history5 = cnn5.fit(train_ds, epochs=20, validation_data=val_ds, class_weight=class_weights_dict, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd8c932-392f-48a6-bf1e-891be8b83557",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn5.save('./saved_models/cnn5.h5')\n",
    "pd.DataFrame(history5.history).to_csv('./saved_models//history5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ed74b-81ec-4693-8803-005e09fa626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Check out the plot of loss vs epoch.\n",
    "plt.figure(figsize = (12, 6));\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history5.history['loss'], c = 'navy', label = 'Training Loss');\n",
    "plt.plot(history5.history['val_loss'], c = 'orange', label = 'Testing Loss');\n",
    "\n",
    "plt.title('''CNN 5 :\n",
    "Binary Crossentropy (loss function),\n",
    "as a Function of Epochs''')\n",
    "plt.xlabel('Epochs');\n",
    "plt.ylabel('Loss Function')\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history5.history['acc'], c = 'navy', label = 'Training Accuracy');\n",
    "plt.plot(history5.history['val_acc'], c = 'orange', label = 'Testing Accuracy');\n",
    "plt.title('''CNN 5: \n",
    "Accuracy Score \n",
    "as a Function of Epochs)''')\n",
    "plt.xlabel('Epochs');\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e1b0b-b0f1-4726-b29d-12d34df4e356",
   "metadata": {},
   "source": [
    "## Loading the Model to Analyze Metrics\n",
    "\n",
    "The CNN has a single output node. The CNN will predict the probabilities for the validation set. The predicted probabilities are thresholded at 0.5 to convert them to class labels (0 or 1). Boolean values are returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4820fd-0485-48ee-877d-9f79ed170a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model & training history\n",
    "cnn5 = load_model('./saved_models/cnn4_saved_model/cnn5.h5')\n",
    "history4 = pd.read_csv('./saved_models/cnn4_saved_model/history5.csv')\n",
    "\n",
    "# Get the true labels from the validation dataset\n",
    "y_true = []\n",
    "for images, labels in val_ds:\n",
    "    y_true.extend(labels.numpy())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "# Predict the probabilities for the validation set\n",
    "y_pred_probs = cnn5.predict(val_ds, verbose=0)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred_classes = (y_pred_probs > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate the F1 score\n",
    "f1 = f1_score(y_true, y_pred_classes)\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9a538-fdbb-46d0-a26e-ad0ec238a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred_probs)\n",
    "roc_auc = roc_auc_score(y_true, y_pred_probs)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--') #baseline of AUC = 0.5\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('CNN 5 Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
