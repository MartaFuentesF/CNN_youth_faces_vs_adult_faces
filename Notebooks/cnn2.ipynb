{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12f76400-4fec-4b28-aa84-5206a3696026",
   "metadata": {},
   "source": [
    "# Distinguishing Adult and Youth Faces Using Convolutional Neural Networks\n",
    "\n",
    "\n",
    "## Notebook CNN2: Second Convolutional Neural Network\n",
    "This section details the development of an advanced Convolutional Neural Network (CNN) incorporating two hidden layers. In this model, the complexity is increased to capture more intricate patterns in the data. However, neither regularization techniques nor data balancing methods are applied at this stage. This iteration aims to assess the impact of additional layers on model performance. Future iterations will introduce parameter adjustments, including regularization and data balancing, to progressively enhance the model's effectiveness and mitigate overfitting.\n",
    "\n",
    "### Important Considerations\n",
    "* These models require significant computing power. Each took 10 hours to fit using an M3 chip and 18GB of memory.\n",
    "* Consider making a separate keras environment\n",
    "* Consider working in GoogleColab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "42d869bc-5a7d-496c-a3c4-c4b46c0828fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5327a4d0-491a-47c5-bca4-8e11ef7d04d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14633 files belonging to 2 classes.\n",
      "Using 11707 files for training.\n",
      "Found 14633 files belonging to 2 classes.\n",
      "Using 2926 files for validation.\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/marta/Documents/data_dir/'\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(256, 256),\n",
    "  batch_size = 32)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(256, 256),\n",
    "  batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15533131-17b9-443f-b462-8ad74c14456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating weights to address the unbalanced classes.\n",
    "# Assisted by Argo Ovsepyan\n",
    "classes = np.array(['PLP', 'POR'])\n",
    "y = [classes[0]] * 5422 + [classes[1]] * 9211\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=y)\n",
    "class_weights_dict = class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a87ba38-3873-4659-b612-0af709901250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 2: input layer + 2 hidden layers, changed filters to 3 and kernel size to 3\n",
    "cnn2 = Sequential()\n",
    "\n",
    "# Convoluting and MaxPooling\n",
    "# input (which includes one hidden layer because Sequential does that)\n",
    "cnn2.add(Conv2D(512, 3, # changed from 2\n",
    "                activation = 'relu',\n",
    "                input_shape = (256, 256, 3)))\n",
    "cnn2.add(MaxPooling2D(2, padding = 'same'))\n",
    "\n",
    "# add our first explicit hidden layer\n",
    "cnn2.add(Conv2D(256, \n",
    "                3, \n",
    "                activation = 'relu',\n",
    "               kernel_regularizer = regularizers.l2(0.01)))\n",
    "cnn2.add(MaxPooling2D(2, padding = 'same'))\n",
    "\n",
    "# adding a second hidden layer\n",
    "cnn2.add(Conv2D(256, \n",
    "                3,\n",
    "                activation = 'relu',\n",
    "               kernel_regularizer = regularizers.l2(0.01)))\n",
    "cnn2.add(MaxPooling2D(2, padding = 'same'))\n",
    "\n",
    "# Output layer, with softmax activation because it's classification\n",
    "# with as many neurons as there are classes\n",
    "cnn2.add(Flatten())\n",
    "cnn2.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# compiling the model\n",
    "cnn2.compile(\n",
    "    loss = 'binary_crossentropy', \n",
    "    optimizer = 'adam', \n",
    "    metrics = ['acc'])\n",
    "\n",
    " # Fit the model\n",
    " history2 = cnn2.fit(train_ds,\n",
    "                    epochs = 10,\n",
    "                    validation_data = val_ds, \n",
    "                    class_weight = class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42577f4-2f23-493d-93f5-8fe9f72878df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2.save('./saved_models/cnn2.h5')\n",
    "pd.DataFrame(history2.history).to_csv('./saved_models//history2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e96ed-1c41-4cde-a2b1-2b1632d2cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the plot of loss vs epoch.\n",
    "plt.figure(figsize = (12, 6));\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history2.history['loss'], c = 'navy', label = 'Training Loss');\n",
    "plt.plot(history2.history['val_loss'], c = 'orange', label = 'Testing Loss');\n",
    "\n",
    "plt.title('''CNN 2 :\n",
    "Binary Crossentropy (loss function),\n",
    "as a Function of Epochs''')\n",
    "plt.xlabel('Epochs');\n",
    "plt.ylabel('Loss Function')\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history2.history['acc'], c = 'navy', label = 'Training Accuracy');\n",
    "plt.plot(history2.history['val_acc'], c = 'orange', label = 'Testing Accuracy');\n",
    "plt.title('''CNN 2: \n",
    "Accuracy Score \n",
    "as a Function of Epochs)''')\n",
    "plt.xlabel('Epochs');\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dc67c8-5ceb-4914-92e5-e0fd9d8dda6b",
   "metadata": {},
   "source": [
    " **CNN 2**: By adding more hidden layers, CNN 2 significantly improved training accuracy. However, the model showed signs of overfitting, as indicated by a lower validation accuracy compared to training accuracy. The lack of regularization meant that while the model could learn from the training data, it struggled to generalize to new, unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
